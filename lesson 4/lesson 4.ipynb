{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e0a0683",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymongo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gy/zpg7q3hs7ms0t6v0mxlxkcdw0000gn/T/ipykernel_45640/2969465793.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpymongo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMongoClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpprint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pymongo'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from pprint import pprint\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6fb6935",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MongoClient' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gy/zpg7q3hs7ms0t6v0mxlxkcdw0000gn/T/ipykernel_45640/3522986203.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMongoClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'localhost'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m27017\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vacancies_db'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhh_vac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhh_vac\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msj_vac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msj_vac\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MongoClient' is not defined"
     ]
    }
   ],
   "source": [
    "client = MongoClient('localhost',27017)\n",
    "db = client['vacancies_db']\n",
    "hh_vac = db.hh_vac\n",
    "sj_vac = db.sj_vac\n",
    "\n",
    "\n",
    "def hh_search(text, page, only_new = 'yes', hh_vac = hh_vac):\n",
    "\n",
    "    user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "    link_hh = ('https://hh.ru/search/vacancy?area=2&st=searchVacancy@enable_snippets=true&')\n",
    "    #main_link = ('localhost/hh.html/')\n",
    "    i = 0\n",
    "    vacs = []\n",
    "\n",
    "    for p in range(page):\n",
    "        html = requests.get(f'{link_hh}&text={text}&page={p}',  headers = user_agent).text\n",
    "        parsed_html = bs(html,'lxml')\n",
    "        vac_list = parsed_html.findAll('div', {'class':'vacancy-serp-item__row vacancy-serp-item__row_header'})\n",
    "        df = pd.DataFrame(columns=['name', 'salary_min', 'salary_max', 'url', 'site'])\n",
    "\n",
    "        for vac in vac_list:\n",
    "            #print(i)\n",
    "            vac_data = {}\n",
    "\n",
    "            main_info = vac.findChild()\n",
    "            link = vac.find('a')\n",
    "            if not link:\n",
    "                url = 'nan'\n",
    "                vac_data['name'] = ''\n",
    "            else:\n",
    "                vac_data['name'] = link.getText()\n",
    "                url = link[\"href\"].split('?')[0]\n",
    "                vac_num = url.split('/')[3]\n",
    "\n",
    "\n",
    "\n",
    "            compensation = vac.findParent().find('div', {'data-qa': 'vacancy-serp__vacancy-compensation'})\n",
    "            salary = 0\n",
    "            salary_min = float('nan')\n",
    "            salary_max = float('nan')\n",
    "            if not compensation:\n",
    "                pass\n",
    "            else:\n",
    "                salary = compensation.getText()\n",
    "                salary = re.sub(r\"\\s+\", \"\", salary)\n",
    "                if salary.find('от') >= 0 :\n",
    "                    salary_min = int(re.findall(r'\\d+',  salary)[0])\n",
    "\n",
    "                elif salary.find('до') >= 0 :\n",
    "                    salary_max = int(re.findall(r'\\d+', salary)[0])\n",
    "\n",
    "                elif salary.find('-') >= 0 :\n",
    "                    salary = re.findall(r'\\d+', salary)\n",
    "                    salary_min = salary[0]\n",
    "                    salary_max = salary[1]\n",
    "\n",
    "                #print('sal', salary)\n",
    "                #print('salary_min', salary_min)\n",
    "                #print('salary_max', salary_max)\n",
    "                vac_data['salary_min'] = salary_min\n",
    "                vac_data['salary_max'] = salary_max\n",
    "                vac_data['url'] = url\n",
    "                vac_data['vac_num'] = vac_num\n",
    "                vac_data['site'] = 'HeadHunter'\n",
    "\n",
    "                vacs.append(vac_data)\n",
    "                df.append(vac_data, ignore_index = True)\n",
    "                if only_new == 'yes':\n",
    "                  if find_in_db('hh', vac_num) == 0:\n",
    "                    hh_vac.insert_one(vac_data)\n",
    "                else:\n",
    "                  # Не слишком продуктивно писать в базу по одной, зато доп. задержка для сайта\n",
    "                  hh_vac.insert_one(vac_data)\n",
    "\n",
    "\n",
    "            i += 1\n",
    "            time.sleep(1)\n",
    "    return(vacs)\n",
    "\n",
    "def sj_search(text, page, only_new = 'yes', sj_vac = sj_vac):\n",
    "\n",
    "\n",
    "\n",
    "    user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "    link_sj = ('https://www.superjob.ru/vacancy/search/?')\n",
    "    #main_link = ('localhost/hh.html/')\n",
    "    i = 0\n",
    "    vacs = []\n",
    "    url_start = 'https://www.superjob.ru'\n",
    "\n",
    "    for p in range(1, page+1):\n",
    "        html = requests.get(f'{link_sj}&keywords={text}&page={p}', headers = user_agent).text\n",
    "        parsed_html = bs(html,'lxml')\n",
    "        vac_list = parsed_html.findAll('div', {'class':'_3syPg _1_bQo _2FJA4'})\n",
    "        df = pd.DataFrame(columns=['name', 'salary_min', 'salary_max', 'url', 'site'])\n",
    "\n",
    "        for vac in vac_list:\n",
    "            #print(i)\n",
    "            vac_data = {}\n",
    "\n",
    "            main_info = vac.findChild()\n",
    "            #print('main_info', main_info)\n",
    "            name = vac.find('div', {'class': '_3mfro CuJz5 PlM3e _2JVkc _3LJqf'}).getText()\n",
    "            vac_data['name'] = name\n",
    "            link = vac.find('a')\n",
    "\n",
    "            if not link:\n",
    "                url = 'nan'\n",
    "                vac_num = 'nan'\n",
    "\n",
    "            else:\n",
    "                url_vac = link['href']\n",
    "                url = f'{url_start}/{url_vac}'\n",
    "                vac_data['url'] = url\n",
    "                vac_data['vac_num'] = url\n",
    "\n",
    "            salary = 0\n",
    "            salary_min = float('nan')\n",
    "            salary_max = float('nan')\n",
    "            compensation = vac.find('span', {'class': '_3mfro _2Wp8I f-test-text-company-item-salary PlM3e _2JVkc _2VHxz'})\n",
    "            if not compensation:\n",
    "                salary = 0\n",
    "            else:\n",
    "                salary = compensation.getText()\n",
    "                if salary.find('от') >= 0:\n",
    "                    salary_min = re.findall(r'\\d+', salary)[0]\n",
    "\n",
    "                #elif salary.find('до') >= 0:\n",
    "                    #salary_max = re.findall(r'\\d+', salary)[0]\n",
    "                elif salary.find('—') >= 0:\n",
    "                    salary = re.findall(r'\\d+', salary)\n",
    "\n",
    "                    salary_min = int(salary[0])*1000\n",
    "                    salary_max = int(salary[2])*1000\n",
    "                elif salary.find('договорённости') >= 0:\n",
    "                    salary_min = 'по договорённости'\n",
    "\n",
    "\n",
    "            vac_data['salary_min'] = salary_min\n",
    "            vac_data['salary_max'] = salary_max\n",
    "            vac_data['url'] = url\n",
    "            vac_data['vac_num'] = url\n",
    "            vac_data['site'] = 'Superjob'\n",
    "\n",
    "            vacs.append(vac_data)\n",
    "            df.append(vac_data, ignore_index=True)\n",
    "            if only_new == 'yes':\n",
    "                if find_in_db('sj', url) == 0:\n",
    "                    sj_vac.insert_one(vac_data)\n",
    "            else:\n",
    "                # Не слишком продуктивно писать в базу по одной, зато доп. задержка для сайта\n",
    "                sj_vac.insert_one(vac_data)\n",
    "\n",
    "\n",
    "            vacs.append(vac_data)\n",
    "            df.append(vac_data, ignore_index=True)\n",
    "            i += 1\n",
    "    return (vacs)\n",
    "\n",
    "           #df.append(vac_data, ignore_index = True)\n",
    "\n",
    "def find_in_db(site, vac_num):\n",
    "  exists = 0\n",
    "  if site == 'hh':\n",
    "    exists = hh_vac.count_documents({'vac_num': vac_num})\n",
    "  return exists\n",
    "\n",
    "def find_salary():\n",
    "  salary = input('Введите минимальную зарплату: ')\n",
    "  expensive_vacs = hh_vac.find({'salary_min':{'$gte':salary}}).sort('salary_min')\n",
    "  print('Вакансии с зарплатой выше чем ', salary)\n",
    "  for item in expensive_vacs:\n",
    "    pprint(item)\n",
    "\n",
    "find_salary()\n",
    "\n",
    "\n",
    "def search_vac(only_new ='yes'):\n",
    "\n",
    "  text = input('Введите вакансию: ')\n",
    "  text = text.replace(' ', '+')\n",
    "  page = int(input('Введите кол-во страниц: '))\n",
    "  #print(hh_search(text, page))\n",
    "  hh_search(text, page, only_new)\n",
    "  sj_search(text, page, only_new)\n",
    "\n",
    "  #print(sj_search(text, page))\n",
    "  df1 = pd.DataFrame.from_dict(hh_search(text, page))\n",
    "  df2 = pd.DataFrame.from_dict(sj_search(text, page))\n",
    "  df = pd.concat([df1, df2], ignore_index=True)\n",
    "  #pprint(df1)\n",
    "  #print(df2)\n",
    "  return df\n",
    "\n",
    "#df = pd.DataFrame(data=vacs)\n",
    "#print(df)\n",
    "print(search_vac('yes'))\n",
    "#vacs_in_db = hh_vac.find()\n",
    "#for item in vacs_in_db:\n",
    "    #pprint(item)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
